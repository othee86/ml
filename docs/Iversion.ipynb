{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iversion.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/othee86/ml/blob/iverson/docs/Iversion.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "jW6E3ez78IRd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# My Notebook\n",
        "This is the first notebook for Machine Learning from Iversion"
      ]
    },
    {
      "metadata": {
        "id": "mDSAh5RL8Vj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "203c6892-f2d2-4b8c-b876-a46733b34e1c"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "slomFm4LVnjx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Notebook option\n",
        "\n",
        "Google Collab\n",
        "https://colab.research.google.com/notebooks/welcome.ipynb#recent=true\n",
        "\n",
        "Google Cloud Platform Datalab\n",
        "https://cloud.google.com/datalab/\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "bjXJc51oXPNi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Science Distribution\n",
        "Anaconda Distribution https://www.anaconda.com/distribution/\n",
        "\n",
        "## Useful tools\n",
        "https://deeplearning4j.org/\n",
        "https://gitter.im/\n",
        "https://databricks.com/\n",
        "https://spark.apache.org/\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "bUA5Oi5qXqb6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Big Data Analytics\n",
        "\n",
        "## Data Ingestion\n",
        "\n",
        "\n",
        "*   SQOOP (SQL Hadoop)\n",
        "\n",
        "\n",
        "*   Flume\n",
        "*   \n",
        "\n",
        "\n",
        "RDBMS\n",
        "* usually TB of data (max)\n",
        "* Limted options to scale\n",
        "* 100% consistent (all client will have same point of view)\n",
        "* lots of database closed source\n",
        "\n",
        "No SQL (Not only SQL) - can scale beyond TBs data\n",
        "* can scale beyond TBs data\n",
        "* Distributed (lot of machines)\n",
        "* many databases  they are eventually consistent\n",
        "* lots of database open source\n",
        "* geo spetial search\n",
        "\n",
        "\n",
        "\n",
        "## Data Storage\n",
        "\n",
        "File System\n",
        "* Hadoop Distributed file system\n",
        "* HBase (Hadoop database)\n",
        "\n",
        "Database\n",
        "\n",
        "## Data Processing\n",
        "* MapReduce\n",
        "* Spark Core\n",
        "* Spark Streaming\n",
        "\n",
        "## Data Analysis\n",
        "* HIVE\n",
        "* PIG\n",
        "* Impala\n",
        "* Spark SQL\n",
        "\n",
        "## Data Exploration\n",
        "* Elastic Search\n",
        "* Sola\n",
        "\n",
        "## Data Visualization\n",
        "* BI tools\n",
        "* D3.js\n",
        "* Kibana\n",
        "* Rest based API\n"
      ]
    },
    {
      "metadata": {
        "id": "G-KunmaSPEFS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "* Data Acquisition\n",
        "* Data Encoding\n",
        "\n",
        "Label encoding\n",
        "\n",
        "One hot encoding\n",
        "\n",
        "* Data Validation\n",
        "* Data Filtering\n",
        "* Handling Missing Data\n",
        "* Data De-Duplication\n",
        "\n",
        "... ...\n",
        "\n",
        "* Data Enrichment (Adding more data)"
      ]
    },
    {
      "metadata": {
        "id": "3ELPwt70T0v1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering\n",
        "\n",
        "* Why feature engineering - effective modeling\n",
        "* Model should not take long time to learn\n"
      ]
    },
    {
      "metadata": {
        "id": "9PTp1YWsXG-s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Spark\n",
        "\n",
        "* framework for distributed processing - scalable machien learning\n",
        "* developed at UCB in 2009\n",
        "* PHD student who created spark, they formed a company \"Databricks\"\n",
        "* unified framework\n",
        "\n",
        "Why Spark\n",
        "\n",
        "* Very fast (100 times faster than MapReduce)\n",
        "* Good for iterative algorithm\n",
        "* integrates very well with Hadoop ecosystem, nosql database etc.\n",
        "* real time analytics is possible\n",
        "* graph processing\n",
        "* lots of programming languages eg. Java, R, Python, SQL, Scala etc.\n",
        "* lots of community support and enterprise support available\n",
        "* spark works with GPU\n",
        "* spark and deep learning library integrate well. eg. DL4J, tensorflow etc.\n",
        "\n",
        "Spark usage\n",
        "\n",
        "* batch mode\n",
        "* interactive mode (shell or jupyter notebooks or Zepplin Notebook)\n",
        "* Ad-hoc querying mode\n",
        "* Real time mode\n",
        "* micro-batch mode\n",
        "\n",
        "lambda architecture\n",
        "https://en.wikipedia.org/wiki/Lambda_architecture\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1PN56sHR2pEA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}