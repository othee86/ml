{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iversion.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/othee86/ml/blob/iverson/docs/Iversion.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "jW6E3ez78IRd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# My Notebook\n",
        "This is the first notebook for Machine Learning from Iversion"
      ]
    },
    {
      "metadata": {
        "id": "mDSAh5RL8Vj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "203c6892-f2d2-4b8c-b876-a46733b34e1c"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "slomFm4LVnjx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Notebook option\n",
        "\n",
        "Google Collab\n",
        "https://colab.research.google.com/notebooks/welcome.ipynb#recent=true\n",
        "\n",
        "Google Cloud Platform Datalab\n",
        "https://cloud.google.com/datalab/\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "bjXJc51oXPNi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Science Distribution\n",
        "Anaconda Distribution https://www.anaconda.com/distribution/\n",
        "\n",
        "## Useful tools\n",
        "\n",
        "https://deeplearning4j.org/\n",
        "\n",
        "https://gitter.im/\n",
        "\n",
        "https://databricks.com/\n",
        "\n",
        "https://spark.apache.org/\n",
        "\n",
        "https://www.confluent.io/product/connectors/\n",
        "\n",
        "http://usefulstuff.io/big-data/\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "bUA5Oi5qXqb6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Big Data Analytics\n",
        "\n",
        "## Data Ingestion\n",
        "\n",
        "\n",
        "*   SQOOP (SQL Hadoop)\n",
        "\n",
        "\n",
        "*   Flume\n",
        "*   \n",
        "\n",
        "\n",
        "RDBMS\n",
        "* usually TB of data (max)\n",
        "* Limted options to scale\n",
        "* 100% consistent (all client will have same point of view)\n",
        "* lots of database closed source\n",
        "\n",
        "No SQL (Not only SQL) - can scale beyond TBs data\n",
        "* can scale beyond TBs data\n",
        "* Distributed (lot of machines)\n",
        "* many databases  they are eventually consistent\n",
        "* lots of database open source\n",
        "* geo spetial search\n",
        "\n",
        "\n",
        "\n",
        "## Data Storage\n",
        "\n",
        "File System\n",
        "* Hadoop Distributed file system\n",
        "* HBase (Hadoop database)\n",
        "\n",
        "Database\n",
        "\n",
        "## Data Processing\n",
        "* MapReduce\n",
        "* Spark Core\n",
        "* Spark Streaming\n",
        "\n",
        "## Data Analysis\n",
        "* HIVE\n",
        "* PIG\n",
        "* Impala\n",
        "* Spark SQL\n",
        "\n",
        "## Data Exploration\n",
        "* Elastic Search\n",
        "* Sola\n",
        "\n",
        "## Data Visualization\n",
        "* BI tools\n",
        "* D3.js\n",
        "* Kibana\n",
        "* Rest based API\n"
      ]
    },
    {
      "metadata": {
        "id": "G-KunmaSPEFS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Data Preprocessing\n",
        "\n",
        "* Data Acquisition\n",
        "* Data Encoding\n",
        "\n",
        "Label encoding\n",
        "\n",
        "One hot encoding\n",
        "\n",
        "* Data Validation\n",
        "* Data Filtering\n",
        "* Handling Missing Data\n",
        "* Data De-Duplication\n",
        "\n",
        "... ...\n",
        "\n",
        "* Data Enrichment (Adding more data)"
      ]
    },
    {
      "metadata": {
        "id": "3ELPwt70T0v1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering\n",
        "\n",
        "* Why feature engineering - effective modeling\n",
        "* Model should not take long time to learn\n"
      ]
    },
    {
      "metadata": {
        "id": "9PTp1YWsXG-s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Spark\n",
        "\n",
        "* framework for distributed processing - scalable machien learning\n",
        "* developed at UCB in 2009\n",
        "* PHD student who created spark, they formed a company \"Databricks\"\n",
        "* unified framework\n",
        "\n",
        "Why Spark\n",
        "\n",
        "* Very fast (100 times faster than MapReduce)\n",
        "* Good for iterative algorithm\n",
        "* integrates very well with Hadoop ecosystem, nosql database etc.\n",
        "* real time analytics is possible\n",
        "* graph processing\n",
        "* lots of programming languages eg. Java, R, Python, SQL, Scala etc.\n",
        "* lots of community support and enterprise support available\n",
        "* spark works with GPU\n",
        "* spark and deep learning library integrate well. eg. DL4J, tensorflow etc.\n",
        "\n",
        "Spark usage\n",
        "\n",
        "* batch mode\n",
        "* interactive mode (shell or jupyter notebooks or Zepplin Notebook)\n",
        "* Ad-hoc querying mode\n",
        "* Real time mode\n",
        "* micro-batch mode\n",
        "\n",
        "lambda architecture\n",
        "https://en.wikipedia.org/wiki/Lambda_architecture\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "-lMCif6JciWw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MapReduce\n",
        "\n",
        "Map ->\n",
        "\n",
        "* filter\n",
        "* extract\n",
        "* transform\n",
        "* parse\n",
        "\n",
        "Reduce ->\n",
        "\n",
        "* statistical"
      ]
    },
    {
      "metadata": {
        "id": "Oej7njxk5QUy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Spark Core vs. Spark SQL\n",
        "\n",
        "Spark core\n",
        "\n",
        "* RDD\n",
        "* low level\n",
        "* SC\n",
        "* All type of data\n",
        "* Messy code\n",
        "\n",
        "Spark SQL\n",
        "\n",
        "* Dataframe (Datasets in scala)\n",
        "* High level (framework will do lot of optimization)\n",
        "* sql context (spark2.x => spark)\n",
        "* only for semi-structure or structured data\n",
        "* clean code eg. named column\n",
        "\n",
        "\n",
        "RDD\n",
        "\n",
        "* lazy (does not load data immediate)\n",
        "\n",
        "DF \n",
        "\n",
        "* lazy for data\n",
        "* eager for schema\n",
        "\n",
        "DF = RDD + schema\n",
        "\n",
        "DF is RDD of row object\n"
      ]
    },
    {
      "metadata": {
        "id": "HrgSQkNcaGka",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Installing Spark\n",
        "\n",
        "Cloudera manager\n",
        "\n",
        "* installation\n",
        "* configuration\n",
        "* monitoring\n",
        "* maintenance\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "hm53veH_eUf7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Day 3\n",
        "\n",
        "what is spark\n",
        "\n",
        "why spark\n",
        "\n",
        "data encoding\n",
        "\n",
        "type of function\n",
        "1 to 1\n",
        "1 to many\n",
        "many to 1\n",
        "\n",
        "spark core vs spark sql\n",
        "\n",
        "lambda architecture\n",
        "\n",
        "seaborn vs mathplot\n",
        "\n",
        "feature engineering\n",
        "\n",
        "logical and physical architecture of mapreduce\n",
        "\n",
        "databrick\n"
      ]
    },
    {
      "metadata": {
        "id": "NxWrzYZ_eiBv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Questions:\n",
        "\n",
        "debug infrasturcture and technique\n",
        "\n",
        "distributed evolutionary algorithm"
      ]
    }
  ]
}